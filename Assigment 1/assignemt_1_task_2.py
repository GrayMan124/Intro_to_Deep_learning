# -*- coding: utf-8 -*-
"""Assignemt_1_task_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15elcWxF8EdXNBrCGCL6iRC4_G83ooUU1
"""

import tensorflow as tf
import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow.keras import layers
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from keras.preprocessing import image

tf.keras.utils.set_random_seed(42)

from google.colab import drive
import pathlib
drive.mount('/content/drive')

def avg_loss_cs(pred,label):
  dist = np.abs(pred.flatten()-label.flatten())
  circle = np.array([np.mod(dist,720),np.mod(-dist,720)]).T
  circle_dist = np.min(circle,axis=1)
  return np.mean(circle_dist)

"""### Uploading the data"""

df = np.load('drive/MyDrive/Intro_to_DP/images.npy')
labels = np.load('drive/MyDrive/Intro_to_DP/labels.npy')

img = df[3]
x = image.img_to_array(img)
print(type(x))
print(x.shape)
plt.imshow(x)

"""Normalizing the input data"""

normalizer_layer = tf.keras.layers.Normalization(axis=1)
normalizer_layer.adapt(df)
output = normalizer_layer(df)

data = np.array(output)

labels_all = labels[:,0]*60 + labels[:,1]

"""## First apporach: Classification"""

def group_class(interval,y_train,y_test):
  y_train_new = y_train//interval
  y_test_new = y_test//interval
  num_class = 720//interval
  y_test_new = tf.keras.utils.to_categorical(y_test_new, num_classes=num_class)
  y_train_new = tf.keras.utils.to_categorical(y_train_new, num_classes=num_class)
  return y_train_new, y_test_new, num_class

X_train, X_test, y_train, y_test = train_test_split(data,labels_all,test_size = 0.2,shuffle = True)

# interval = 30
# y_train, y_test_2, num_class = group_class(interval,y_train,y_test)

# interval = 15
# y_train, y_test_2, num_class = group_class(interval,y_train,y_test)

interval = 10
y_train, y_test_2, num_class = group_class(interval,y_train,y_test)

# interval = 5
# y_train, y_test_2, num_class = group_class(interval,y_train,y_test)

# interval = 2
# y_train, y_test_2, num_class = group_class(interval,y_train,y_test)

# interval = 1
# y_train, y_test_2, num_class = group_class(interval,y_train,y_test)

model = tf.keras.Sequential([
    layers.Conv2D(15, ((8,8)),strides = 3, activation = 'relu', input_shape = (150,150,1)),
    # layers.MaxPooling2D(2,2),
    # layers.Conv2D(75, ((4,4)),activation = 'relu', input_shape = (145,145,20)),
    # layers.Conv2D(40, ((5,5)),activation = 'relu', input_shape = (145,145,20)),
    layers.MaxPooling2D(pool_size = (3,3),strides = 2),

    layers.Conv2D(30, ((4,4)), activation = 'relu', input_shape = (72,72,40)),
    # layers.MaxPooling2D(2,2),
    layers.Conv2D(45, (3,3), activation = 'relu', input_shape = (34,34,100)),
    layers.Conv2D(45, ((3,3)), activation = 'relu', input_shape = (68,68,75)),
    layers.MaxPooling2D(pool_size=(2,2)),

    layers.Conv2D(80, (3,3), activation = 'relu', input_shape = (34,34,100)),
    # layers.MaxPooling2D(2,2),

    layers.Conv2D(80, (3,3), activation = 'relu', input_shape = (3,3,75)),
    # layers.MaxPooling2D(2,2),

    layers.Conv2D(80, (3,3), activation = 'relu', input_shape = (5,5,200)),
    # layers.Conv2D(400, (3,3), activation = 'relu', input_shape = (5,5,200)),
    # layers.Conv2D(200, (3,3), activation = 'relu', input_shape = (5,5,200)),
    # layers.Conv2D(150, (3,3), activation = 'relu', input_shape = (3,3,200)),
    # layers.Conv2D(120, (3,3), activation = 'relu', input_shape = (150,150,1)),
    # layers.MaxPooling2D(2,2),

    layers.Flatten(),
    layers.Dense(512, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(256, activation='relu'),
    layers.Dense(num_class, activation = 'softmax')
])

opt = tf.keras.optimizers.Adam()
early_stopping = tf.keras.callbacks.EarlyStopping(patience = 6, verbose = 1)
model.compile(optimizer='adam',
              loss=tf.keras.losses.categorical_crossentropy,
              metrics=['accuracy'])

model.summary()

history = model.fit(X_train, y_train, epochs=50, batch_size = 128, validation_data = (X_test, y_test_2), callbacks = [early_stopping])

plt.figure(figsize=(16,5))
plt.plot(history.history['loss'],color='blue')
plt.plot(history.history['val_loss'],color='orange')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.show()

pred = np.argmax(model.predict(X_test),axis =1)

preds_1 = pred*interval

np.save('drive/MyDrive/Intro_to_DP/labels_1',preds_1)
np.save('drive/MyDrive/Intro_to_DP/preds_1',y_test)

preds_1 = np.load('drive/MyDrive/Intro_to_DP/preds_1.npy')
y_test = np.load('drive/MyDrive/Intro_to_DP/labels_1.npy')

avg_loss_cs(preds_1,y_test)

"""## Second Approach - Regression"""

def scaler(X,max,min):
  X_scaled = (X - np.min(X)) / (np.max(X) - np.min(X)) * (max - min) + min
  return X_scaled

"""Here is the data transformed into a"""

scaled_labels =scaler(labels_all,12,0)
scaled_labels.astype(float)

X_train, X_test, y_train, y_test = train_test_split(data,scaled_labels,test_size = 0.2,random_state = 0,shuffle = True)

model = tf.keras.Sequential([
    layers.Conv2D(15, ((8,8)),strides = 3, activation = 'tanh', input_shape = (150,150,1)),
    # layers.MaxPooling2D(2,2),
    # layers.Conv2D(75, ((4,4)),activation = 'relu', input_shape = (145,145,20)),
    # layers.Conv2D(40, ((5,5)),activation = 'relu', input_shape = (145,145,20)),
    layers.MaxPooling2D(pool_size = (3,3),strides = 2),

    layers.Conv2D(30, ((4,4)), activation = 'tanh', input_shape = (72,72,40)),
    # layers.MaxPooling2D(2,2),
    layers.Conv2D(45, (3,3), activation = 'tanh', input_shape = (34,34,100)),
    layers.Conv2D(45, ((3,3)), activation = 'tanh', input_shape = (68,68,75)),
    layers.MaxPooling2D(pool_size=(2,2)),

    layers.Conv2D(80, (3,3), activation = 'tanh', input_shape = (34,34,100)),
    # layers.MaxPooling2D(2,2),

    layers.Conv2D(80, (3,3), activation = 'tanh', input_shape = (3,3,75)),
    # layers.MaxPooling2D(2,2),

    layers.Conv2D(80, (3,3), activation = 'tanh', input_shape = (5,5,200)),
    # layers.Conv2D(400, (3,3), activation = 'relu', input_shape = (5,5,200)),
    # layers.Conv2D(200, (3,3), activation = 'relu', input_shape = (5,5,200)),
    # layers.Conv2D(150, (3,3), activation = 'relu', input_shape = (3,3,200)),
    # layers.Conv2D(120, (3,3), activation = 'relu', input_shape = (150,150,1)),
    # layers.MaxPooling2D(2,2),

    layers.Flatten(),
    layers.Dense(512, activation='tanh'),
    layers.Dropout(0.3),
    layers.Dense(256, activation='tanh'),
    layers.Dense(1)
])

model.summary()

# model.compile(optimizer=tf.keras.optimizers.RMSprop(),
#               loss=tf.keras.losses.MeanSquaredError(),
#               metrics=['mse'])
model.compile(optimizer='adam',
              loss=tf.keras.losses.MeanSquaredError(),
              metrics=['mse'])

history = model.fit(X_train, y_train, epochs=50, batch_size = 128, validation_data = (X_test, y_test))

plt.figure(figsize=(16,5))
plt.plot(history.history['loss'],color='blue')
plt.plot(history.history['val_loss'],color='orange')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.show()

pred = model.predict(X_test)
preds_2 = pred*60

np.save('drive/MyDrive/Intro_to_DP/preds_2',preds_2)
np.save('drive/MyDrive/Intro_to_DP/labels_2',y_test)

preds_2 = np.load('drive/MyDrive/Intro_to_DP/preds_2.npy')
y_test = np.load('drive/MyDrive/Intro_to_DP/labels_2.npy')

la = y_test*60

la

avg_loss_cs(preds_2,la)

"""## Third Approach: Multi head model

Here is the model that uses one convulitional network and then the outputs are based on two different fully conected linear networks

"""

labels_h = labels[:,0]
labels_m = labels[:,1]//5

labels_h = tf.keras.utils.to_categorical(labels_h, num_classes=12)
labels_m = tf.keras.utils.to_categorical(labels_m, num_classes=12)

labels_m.shape

tmp = np.hstack([labels_h,labels_m])

tmp.shape

X_train, X_test, y_train, y_test = train_test_split(data,tmp,test_size = 0.2,random_state = 0)

input = tf.keras.layers.Input(shape = [150,150])
cnn_out  = tf.keras.Sequential([
    layers.Conv2D(15, ((8,8)),strides = 3, activation = 'relu', input_shape = (150,150,1)),
    # layers.MaxPooling2D(2,2),
    # layers.Conv2D(75, ((4,4)),activation = 'relu', input_shape = (145,145,20)),
    # layers.Conv2D(40, ((5,5)),activation = 'relu', input_shape = (145,145,20)),
    layers.MaxPooling2D(pool_size = (3,3),strides = 2),

    layers.Conv2D(30, ((4,4)), activation = 'relu', input_shape = (72,72,40)),
    # layers.MaxPooling2D(2,2),
    layers.Conv2D(45, (3,3), activation = 'relu', input_shape = (34,34,100)),
    layers.Conv2D(45, ((3,3)), activation = 'relu', input_shape = (68,68,75)),
    layers.MaxPooling2D(pool_size=(2,2)),

    layers.Conv2D(80, (3,3), activation = 'relu', input_shape = (34,34,100)),
    # layers.MaxPooling2D(2,2),

    layers.Conv2D(80, (3,3), activation = 'relu', input_shape = (3,3,75)),
    # layers.MaxPooling2D(2,2),

    layers.Conv2D(80, (3,3), activation = 'relu', input_shape = (5,5,200)),
    # layers.Conv2D(400, (3,3), activation = 'relu', input_shape = (5,5,200)),
    # layers.Conv2D(200, (3,3), activation = 'relu', input_shape = (5,5,200)),
    # layers.Conv2D(150, (3,3), activation = 'relu', input_shape = (3,3,200)),
    # layers.Conv2D(120, (3,3), activation = 'relu', input_shape = (150,150,1)),
    # layers.MaxPooling2D(2,2),

    layers.Flatten()
])(input)

# minutes_out = layers.Dense(1,activation = 'softmax')(cnn_out)

hours_out = tf.keras.Sequential([ layers.Dense(512, activation='relu'),
      layers.Dense(256, activation='relu'),
      layers.Dense(12,activation = 'softmax')])(cnn_out)

minutes_out = tf.keras.Sequential([ layers.Dense(512, activation='relu'),
      layers.Dense(256, activation='relu'),
      layers.Dense(12,activation = 'softmax')])(cnn_out)

model = tf.keras.models.Model(inputs = input, outputs = [hours_out,minutes_out])

model.summary()

# model = MultiHeadModel()

model.compile(loss=[tf.keras.losses.categorical_crossentropy,tf.keras.losses.categorical_crossentropy], loss_weights=[0.6, 0.4], optimizer="adam", metrics = 'accuracy')

y_train[:,12].shape

history = model.fit(X_train,[y_train[:,:12],y_train[:,12:]],epochs = 40, batch_size = 128, validation_data = (X_test, [y_test[:,:12],y_test[:,12:]]))

plt.figure(figsize=(16,5))
plt.plot(history.history['loss'],color='blue')
plt.plot(history.history['val_loss'],color='orange')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.show()

preds = model.predict(X_test)

pred_arr = np.array(preds)

preds_h = np.argmax(pred_arr[0],axis=1)
preds_m = np.argmax(pred_arr[1],axis=1)

np.save('drive/MyDrive/Intro_to_DP/preds_3_m',preds_m)
np.save('drive/MyDrive/Intro_to_DP/preds_3_h',preds_h)
np.save('drive/MyDrive/Intro_to_DP/labels_3',y_test)

preds = preds_m*5 + preds_h *60

y_h = y_test[:,:12]
y_m = y_test[:,12:]

y_test_h = np.argmax(y_h,axis=1)
y_test_m = np.argmax(y_m,axis=1)
y_label = y_test_m*5 + y_test_h*60

"""Avarge common sense error"""

avg_loss_cs(preds,y_label)

"""## Approach 4: Sin and Cosin representation

We can represent the unit circle as the (sinx(x),cosin(x)), using that we can create the model that reutrns two outputs - x for the hours, and x for the min, that way we can predict the results as simply getting the hour and minute coresponding to that position
"""

def get_time(h,m):
  h = h*np.pi + np.pi
  m = m*np.pi + np.pi
  one_unit = np.pi/6
  hour = h//one_unit
  minute = (m/one_unit)*5
  return [hour,minute] , np.array(hour*60+minute)

labels_hours = (labels[:,0]*10+(labels[:,1]*5/6)//10)*np.pi/60
labels_minutes = (labels[:,1]*2)*np.pi/60

labels_hours = labels_hours - np.pi
labels_minutes = labels_minutes - np.pi
labels_hours = labels_hours/np.pi
labels_minutes = labels_minutes/np.pi

labels_minutes

tmp = np.array([labels_hours,labels_minutes]).T

X_train, X_test, y_train, y_test = train_test_split(data,tmp,test_size = 0.2,random_state = 0)

input = tf.keras.layers.Input(shape = [150,150])
cnn_out  = tf.keras.Sequential([
    layers.Conv2D(15, ((8,8)),strides = 3, activation = 'tanh', input_shape = (150,150,1)),
    # layers.MaxPooling2D(2,2),
    # layers.Conv2D(75, ((4,4)),activation = 'relu', input_shape = (145,145,20)),
    # layers.Conv2D(40, ((5,5)),activation = 'relu', input_shape = (145,145,20)),
    layers.MaxPooling2D(pool_size = (3,3),strides = 2),

    layers.Conv2D(30, ((4,4)), activation = 'tanh', input_shape = (72,72,40)),
    # layers.MaxPooling2D(2,2),
    layers.Conv2D(45, (3,3), activation = 'tanh', input_shape = (34,34,100)),
    layers.Conv2D(45, ((3,3)), activation = 'tanh', input_shape = (68,68,75)),
    layers.MaxPooling2D(pool_size=(2,2)),

    layers.Conv2D(80, (3,3), activation = 'tanh', input_shape = (34,34,100)),
    # layers.MaxPooling2D(2,2),

    layers.Conv2D(80, (3,3), activation = 'tanh', input_shape = (3,3,75)),
    # layers.MaxPooling2D(2,2),

    layers.Conv2D(80, (3,3), activation = 'tanh', input_shape = (5,5,200)),
    # layers.Conv2D(400, (3,3), activation = 'relu', input_shape = (5,5,200)),
    # layers.Conv2D(200, (3,3), activation = 'relu', input_shape = (5,5,200)),
    # layers.Conv2D(150, (3,3), activation = 'relu', input_shape = (3,3,200)),
    # layers.Conv2D(120, (3,3), activation = 'relu', input_shape = (150,150,1)),
    # layers.MaxPooling2D(2,2),

    layers.Flatten()
])(input)

# minutes_out = layers.Dense(1,activation = 'softmax')(cnn_out)

hours_out = tf.keras.Sequential([ layers.Dense(512, activation='tanh'),
      layers.Dense(256, activation='tanh'),
      layers.Dense(1, activation='tanh')])(cnn_out)

minutes_out = tf.keras.Sequential([ layers.Dense(512, activation='tanh'),
      layers.Dense(256, activation='tanh'),
      layers.Dense(1, activation='tanh')])(cnn_out)

model = tf.keras.models.Model(inputs = input, outputs = [hours_out,minutes_out])

model.summary()

model.compile(loss=['mse','mse'], loss_weights=[0.6, 0.4], optimizer="adam")

history = model.fit(X_train,[y_train[:,0],y_train[:,1]],epochs = 50, batch_size = 256, validation_data = (X_test, [y_test[:,0],y_test[:,1]]) )

pred = model.predict(X_test)

hour_arr = np.array(pred[0])
minute_arr = np.array(pred[1])

time, minutes = get_time(hour_arr,minute_arr)
time_label, minute_label = get_time(y_test[:,0],y_test[:,1])

np.save('pred_4',minutes)
np.save('label_4',minute_label)

pred_4 = np.load('pred_4.npy')
label_4 = np.load('label_4.npy')

avg_loss_cs(pred_4,label_4)

